llamav2_7b:
  batch_size: 1
  completion_parser_kwargs:
    outputs_to_match:
      1: Output \(a\)
      1.5: Tie
      2: Output \(b\)
  completions_kwargs:
    batch_size: 4
    is_fast_tokenizer: true
    max_new_tokens: 20
    model_kwargs:
      load_in_8bit: true
    model_name: meta-llama/Llama-2-7b-chat-hf
  fn_completions: huggingface_local_completions
  prompt_template: huggingface_models/basic_prompt.txt
